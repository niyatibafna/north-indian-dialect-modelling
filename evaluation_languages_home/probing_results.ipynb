{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-colleague",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-mobility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assisted-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def get_args(self):\n",
    "        '''Parses commandline arguments'''\n",
    "\n",
    "        parser = argparse.ArgumentParser(description = \\\n",
    "        \"Evalute predicted lexicon against gold lexicon\")\n",
    "        parser.add_argument(\"--gold_lexicon\", type = str, \\\n",
    "        required = True, help = \"Path to gold lexicon\")\n",
    "        parser.add_argument(\"--pred_lexicon\", type = str, \\\n",
    "        required = True, help = \"Path to predicted lexicon\")\n",
    "        parser.add_argument(\"--eval_type\", type = str, \\\n",
    "        default = \"loose\", help = \"Type of evaluation: {loose, hard, softgold}\")\n",
    "        parser.add_argument(\"--OUTPATH\", type=str, \\\n",
    "        help = \"Path to JSON file to store results\")\n",
    "\n",
    "        return parser.parse_args()\n",
    "\n",
    "    def read_files(self, filepath):\n",
    "\n",
    "        with open(filepath) as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def eval(self, gold_lexicon, pred_lexicon, type = \"loose\"):\n",
    "        '''\n",
    "        Basic accuracy-based evaluation\n",
    "        (type) loose: Considers any gold option equally correct\n",
    "        (type) hard: Considers only the best gold option to be correct\n",
    "        '''\n",
    "        accuracy, found = 0, 0\n",
    "        \n",
    "        correct = dict()\n",
    "        \n",
    "        for word in gold_lexicon:\n",
    "            if word not in pred_lexicon:\n",
    "                continue\n",
    "            found += 1\n",
    "            # best_pred = max(pred_lexicon[word].keys(), key = lambda x:pred_lexicon[word][x])\n",
    "            #For now, pred_targets only contains a single element\n",
    "            # so it is irrelevant whether we do intersection\n",
    "            # or check whether all pred targets lie in gold targets\n",
    "            if type==\"loose\":\n",
    "                if set(pred_lexicon[word].keys()).intersection(set(gold_lexicon[word].keys())):\n",
    "                    accuracy += 1\n",
    "                    correct[word] = {\"gold\":set(gold_lexicon[word].keys()), \\\n",
    "                                     \"pred\":set(pred_lexicon[word].keys()), \\\n",
    "                                     \"both\":set(pred_lexicon[word].keys()).intersection(set(gold_lexicon[word].keys())) \\\n",
    "                                    }\n",
    "                    \n",
    "\n",
    "            elif type==\"hard\":\n",
    "                best_gold_score = max(gold_lexicon[word].values())\n",
    "                best_golds = {word for word in gold_lexicon if gold_lexicon[word]==best_gold_score}\n",
    "                if best_pred in best_golds:\n",
    "                    accuracy += 1\n",
    "\n",
    "            elif type==\"softgold\":\n",
    "                best_gold_score = max(gold_lexicon[word].values())\n",
    "                if best_pred in gold_lexicon[word]:\n",
    "                    accuracy += gold_lexicon[word][best_pred]/best_gold_score\n",
    "\n",
    "        result = {\n",
    "        \"accuracy\":accuracy/found,\n",
    "        \"found\":found,\n",
    "        \"total\":len(gold_lexicon)\n",
    "        }\n",
    "        return result, correct\n",
    "\n",
    "    def save_results(self, lang, result, OUTPATH):\n",
    "\n",
    "        try:\n",
    "            results = self.read_files(OUTPATH)\n",
    "\n",
    "        except:\n",
    "            results = dict()\n",
    "        results[lang] = result\n",
    "        with open(OUTPATH, \"w\") as f:\n",
    "            json.dump(results, f, ensure_ascii = False, indent=2)\n",
    "\n",
    "    def driver(self, gold_lexicon, pred_lexicon, eval_type, OUTPATH=None):\n",
    "        # Get the target language (currently, we take anchor as source)\n",
    "        lang = gold_lexicon.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]\n",
    "        # Read lexicons\n",
    "        gold_lexicon = self.read_files(gold_lexicon)\n",
    "        pred_lexicon = self.read_files(pred_lexicon)\n",
    "        # Evaluate\n",
    "        result = self.eval(gold_lexicon, pred_lexicon, type = eval_type)\n",
    "#         if OUTPATH:\n",
    "#             self.save_results(lang, result, OUTPATH)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def main(self):\n",
    "        args = self.get_args()\n",
    "        self.driver(args.gold_lexicon, args.pred_lexicon, \\\n",
    "        args.eval_type, args.OUTPATH)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     obj = Evaluation()\n",
    "#     obj.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "lined-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"bhojpuri\"\n",
    "f0 = \"../mli_od/lexicons_ned_top5/hindi-urdu_{}.json\".format(lang)\n",
    "f1 = \"../mli_od/lexicons_jw_top5/hindi-urdu_{}.json\".format(lang)\n",
    "f2 = \"../mli_em_od/lexicons_top5/hindi-urdu_{}.json\".format(lang)\n",
    "f3 = \"../mli_sem_od/lexicons_K50_top5/hindi-urdu_{}.json\".format(lang)\n",
    "f4 = \"../mli_sem_emod/lexicons_top5/hindi-urdu_{}.json\".format(lang)\n",
    "gold = \"eval_data/lexicons/hindi-urdu_source/hindi-urdu_{}.json\".format(lang)\n",
    "eval_type = \"loose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "vulnerable-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "located-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NED {'accuracy': 0.3130434782608696, 'found': 115, 'total': 139}\n",
      "JW {'accuracy': 0.28695652173913044, 'found': 115, 'total': 139}\n",
      "EMT {'accuracy': 0.3217391304347826, 'found': 115, 'total': 139}\n",
      "SEM_JW {'accuracy': 0.30434782608695654, 'found': 115, 'total': 139}\n",
      "SEM_EMT {'accuracy': 0.2956521739130435, 'found': 115, 'total': 139}\n"
     ]
    }
   ],
   "source": [
    "apps = {\"NED\":f0, \"JW\":f1, \"EMT\":f2, \"SEM_JW\":f3, \"SEM_EMT\":f4}\n",
    "all_results = dict()\n",
    "for app, f in apps.items():\n",
    "    gold_lexicon = obj.read_files(gold)\n",
    "    pred_lexicon = obj.read_files(f)\n",
    "    res, correct = obj.eval(gold_lexicon, pred_lexicon, type = eval_type)\n",
    "    all_results[app] = {\"res\":res, \"corr\":correct}\n",
    "    print(app, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-shelter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dense-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "लिखा {'gold': {'लिखलास', 'लिखल', 'लिखला'}, 'pred': {'लिखाई', 'लिखना', 'लिखा', 'लिखता', 'लिखला'}, 'both': {'लिखला'}}\n",
      "करते {'gold': {'करे'}, 'pred': {'करते', 'करे', 'कतरे', 'कुर्ते', 'करत'}, 'both': {'करे'}}\n",
      "2 33\n"
     ]
    }
   ],
   "source": [
    "non_id = 0\n",
    "for word, d in all_results[\"od\"][\"corr\"].items():\n",
    "    for b in d[\"both\"]:\n",
    "        if word != b:\n",
    "            print(word, all_results[\"od\"][\"corr\"][word])\n",
    "            non_id += 1\n",
    "\n",
    "print(non_id, len(all_results[\"od\"][\"corr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "champion-press",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "क्या {'gold': {'का', 'करे', 'कर'}, 'pred': {'कहा', 'क्या', 'कला', 'का'}, 'both': {'का'}}\n",
      "तुम {'gold': {'तू'}, 'pred': {'तू', 'तुम', 'तु', 'त'}, 'both': {'तू'}}\n",
      "मैं {'gold': {'हम', 'में'}, 'pred': {'मैं', 'सें', 'ं', 'में'}, 'both': {'में'}}\n",
      "को {'gold': {'के'}, 'pred': {'कि', 'का', 'के', 'को'}, 'both': {'के'}}\n",
      "कितना {'gold': {'केतना'}, 'pred': {'कितना', 'कतना', 'कातना', 'केतना'}, 'both': {'केतना'}}\n",
      "की {'gold': {'राज्य', 'का'}, 'pred': {'की', 'कि', 'का', 'के'}, 'both': {'का'}}\n",
      "6 37\n"
     ]
    }
   ],
   "source": [
    "non_id = 0\n",
    "for word, d in all_results[\"emod\"][\"corr\"].items():\n",
    "    for b in d[\"both\"]:\n",
    "        if word != b:\n",
    "            print(word, all_results[\"emod\"][\"corr\"][word])\n",
    "            non_id += 1\n",
    "\n",
    "print(non_id, len(all_results[\"emod\"][\"corr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "norman-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "वहाँ {'gold': {'यहाँ', 'लोग'}, 'pred': {'वहां', 'तहाँ', 'वहाँ', 'यहाँ', 'जहाँ'}, 'both': {'यहाँ'}}\n",
      "को {'gold': {'के'}, 'pred': {'का', 'के', 'जो', 'की', 'को'}, 'both': {'के'}}\n",
      "कैसी {'gold': {'कैसन'}, 'pred': {'कैसा', 'कैसन', 'बैसी', 'कैसी', 'कैसो'}, 'both': {'कैसन'}}\n",
      "3 35\n"
     ]
    }
   ],
   "source": [
    "non_id = 0\n",
    "for word, d in all_results[\"sem_od\"][\"corr\"].items():\n",
    "    for b in d[\"both\"]:\n",
    "        if word != b:\n",
    "            print(word, all_results[\"sem_od\"][\"corr\"][word])\n",
    "            non_id += 1\n",
    "\n",
    "print(non_id, len(all_results[\"sem_od\"][\"corr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "assisted-variance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "सकते {'gold': {'सका'}, 'pred': {'सकती', 'सकता', 'सका', 'सकते', 'सको'}, 'both': {'सका'}}\n",
      "वहाँ {'gold': {'यहाँ', 'लोग'}, 'pred': {'जहाँ', 'वहीं', 'वहाँ', 'यहाँ', 'वह'}, 'both': {'यहाँ'}}\n",
      "2 34\n"
     ]
    }
   ],
   "source": [
    "non_id = 0\n",
    "for word, d in all_results[\"sem_emod\"][\"corr\"].items():\n",
    "    for b in d[\"both\"]:\n",
    "        if word != b:\n",
    "            print(word, all_results[\"sem_emod\"][\"corr\"][word])\n",
    "            non_id += 1\n",
    "\n",
    "print(non_id, len(all_results[\"sem_emod\"][\"corr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aging-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "दोपहर {'gold': {'दोपहर', 'मे'}, 'pred': {'द', 'दोपहरी', 'दुपहर', 'धूप', 'दोपहर'}, 'both': {'दोपहर'}}\n",
      "सकते {'gold': {'सका'}, 'pred': {'सकती', 'सकता', 'सका', 'सकते', 'सको'}, 'both': {'सका'}}\n",
      "वहाँ {'gold': {'यहाँ', 'लोग'}, 'pred': {'जहाँ', 'वहीं', 'वहाँ', 'यहाँ', 'वह'}, 'both': {'यहाँ'}}\n"
     ]
    }
   ],
   "source": [
    "for word, d in all_results[\"SEM_EMT\"][\"corr\"].items():\n",
    "    if word not in all_results[\"NED\"][\"corr\"]:\n",
    "        print(word, all_results[\"SEM_EMT\"][\"corr\"][word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "legendary-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'सोये': 1.0, 'सोभे': 0.8500000000000001, 'सोझे': 0.8500000000000001, 'सोने': 0.8500000000000001, 'सो': 0.8500000000000001}\n",
      "{'सो': -0.05207981979827417, 'सोये': -7.4355311687131325, 'सब': -9.654800060333967, 'सर': -9.654800060333967}\n",
      "{'सोये': -0.0, 'होये': -0.516082356373469, 'सोया': -0.5234620988368988, 'रोये': -0.549056887626648, 'धोये': -0.5537111659844716}\n",
      "{'सोये': -2.4813055518103906, 'स': -5.283347210041681, 'सोए': -11.40666876898273, 'सोया': -12.121608503495125, 'सोयं': -12.121608503495125}\n",
      "{'गेल': 1, 'सत्ला': 2, 'हा': 1}\n"
     ]
    }
   ],
   "source": [
    "word = \"सोये\"\n",
    "pred_lexicon1 = obj.read_files(apps[\"od\"])\n",
    "pred_lexicon2 = obj.read_files(apps[\"emod\"])\n",
    "pred_lexicon3 = obj.read_files(apps[\"sem_od\"])\n",
    "pred_lexicon4 = obj.read_files(apps[\"sem_emod\"])\n",
    "print(pred_lexicon1[word])\n",
    "print(pred_lexicon2[word])\n",
    "print(pred_lexicon3[word])\n",
    "print(pred_lexicon4[word])\n",
    "print(gold_lexicon[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aggregate-satellite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'कितना': 1.0, 'कतना': 0.94, 'कतिना': 0.94, 'किनार': 0.88, 'कितने': 0.88}\n",
      "{'कितना': -1.728983063083883, 'कतना': -10.01525251586695, 'केतना': -10.01525251586695, 'कातना': -10.01525251586695}\n",
      "{'कितना': -0.0, 'जितना': -0.5228662371635437, 'कितनी': -0.5454433393478393, 'कितने': -0.564395432472229, 'इतना': -0.5961363782485326}\n",
      "{'कितना': -0.5733946293728067, 'कितने': -2.497571134177482, 'जितना': -11.084716542114833, 'कितनी': -12.034405554390837, 'इतना': -13.184235842520081}\n"
     ]
    }
   ],
   "source": [
    "word = \"कितना\"\n",
    "pred_lexicon1 = obj.read_files(apps[\"od\"])\n",
    "pred_lexicon2 = obj.read_files(apps[\"emod\"])\n",
    "pred_lexicon3 = obj.read_files(apps[\"sem_od\"])\n",
    "pred_lexicon4 = obj.read_files(apps[\"sem_emod\"])\n",
    "print(pred_lexicon1[word])\n",
    "print(pred_lexicon2[word])\n",
    "print(pred_lexicon3[word])\n",
    "print(pred_lexicon4[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "different-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'कहानी': 1.0, 'कहनी': 0.9466666666666665, 'कानी': 0.94, 'हानी': 0.9333333333333332, 'कहा': 0.8933333333333333}\n",
      "{'कहानी': 0.0, 'कहतानी': -10.139586815010555, 'करानी': -10.171413246622231, 'कानी': -10.171413246622231}\n",
      "{'कहानी': -0.0, 'हानी': -0.3273595492045085, 'रामकहानी': -0.3636296724279723, 'चुहानी': -0.4890451868375142, 'कानी': -0.49181364297866825}\n",
      "{'कहानी': -1.6559746531357284, 'हानी': -12.167296565877754, 'सुहानी': -17.141049463457836, 'घानी': -22.38807353561832, 'नानी': -22.38807353561832}\n"
     ]
    }
   ],
   "source": [
    "word = \"कहानी\"\n",
    "pred_lexicon1 = obj.read_files(apps[\"od\"])\n",
    "pred_lexicon2 = obj.read_files(apps[\"emod\"])\n",
    "pred_lexicon3 = obj.read_files(apps[\"sem_od\"])\n",
    "pred_lexicon4 = obj.read_files(apps[\"sem_emod\"])\n",
    "print(pred_lexicon1[word])\n",
    "print(pred_lexicon2[word])\n",
    "print(pred_lexicon3[word])\n",
    "print(pred_lexicon4[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "historical-maria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'जवाब': 1.0, 'जाब': 0.9249999999999999, 'जवना': 0.8666666666666667, 'जव': 0.8666666666666667, 'जवान': 0.8666666666666667}\n",
      "{'जाब': -0.06342435270371753, 'जवाब': -2.788761581485382, 'बाब': -9.926870855702662, 'दाब': -9.926870855702662}\n",
      "{'जवाब': -0.0, 'वाब': -0.40016142527262377, 'जबाब': -0.5223091900348663, 'जवाल': -0.5513108452161153, 'नवाब': -0.5664635797341664}\n",
      "{'जवाब': -0.3516394750572899, 'वाब': -2.7024857716159985, 'जबाब': -3.1581863725111723, 'कवाब': -10.247346840274457, 'बताब': -14.99303185187371}\n",
      "{'उत्तर': 1}\n"
     ]
    }
   ],
   "source": [
    "word = \"जवाब\"\n",
    "pred_lexicon1 = obj.read_files(apps[\"od\"])\n",
    "pred_lexicon2 = obj.read_files(apps[\"emod\"])\n",
    "pred_lexicon3 = obj.read_files(apps[\"sem_od\"])\n",
    "pred_lexicon4 = obj.read_files(apps[\"sem_emod\"])\n",
    "print(pred_lexicon1[word])\n",
    "print(pred_lexicon2[word])\n",
    "print(pred_lexicon3[word])\n",
    "print(pred_lexicon4[word])\n",
    "print(gold_lexicon[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "educated-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ज्यादा': 1.0, 'ज्यादातर': 0.9249999999999999, 'ज्यादे': 0.9, 'मर्यादा': 0.8492063492063492, 'याद': 0.8333333333333334}\n",
      "{'ज्यादा': -3.6642873167588736, 'जादा': -8.917683687330632, 'जामा': -10.07190279914727, 'ज़्यादा': -13.80387413176943}\n",
      "{'ज्यादा': -0.0, 'ज्यादातर': -0.30796434581279764, 'ज़्यादा': -0.3627715059689113, 'ज्यादे': -0.37114316821098325, 'मर्यादा': -0.59316729103762}\n",
      "{'ज्यादा': -0.4545150852530514, 'ज़्यादा': -10.675292054993621, 'ज्यादातर': -14.958532819651762, 'ज्यादेतर': -16.82530244250128, 'जितना': -34.74932816807329}\n",
      "{'जयदा': 1, 'लोग': 1, 'हैं': 1}\n"
     ]
    }
   ],
   "source": [
    "word = \"ज्यादा\"\n",
    "pred_lexicon1 = obj.read_files(apps[\"od\"])\n",
    "pred_lexicon2 = obj.read_files(apps[\"emod\"])\n",
    "pred_lexicon3 = obj.read_files(apps[\"sem_od\"])\n",
    "pred_lexicon4 = obj.read_files(apps[\"sem_emod\"])\n",
    "print(pred_lexicon1[word])\n",
    "print(pred_lexicon2[word])\n",
    "print(pred_lexicon3[word])\n",
    "print(pred_lexicon4[word])\n",
    "print(gold_lexicon[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "sacred-chile",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'od'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-5484fe15805d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"कहानी\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_lexicon1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"od\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_lexicon2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emod\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_lexicon3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sem_od\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_lexicon4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sem_emod\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'od'"
     ]
    }
   ],
   "source": [
    "word = \"कहानी\"\n",
    "pred_lexicon1 = obj.read_files(apps[\"od\"])\n",
    "pred_lexicon2 = obj.read_files(apps[\"emod\"])\n",
    "pred_lexicon3 = obj.read_files(apps[\"sem_od\"])\n",
    "pred_lexicon4 = obj.read_files(apps[\"sem_emod\"])\n",
    "print(pred_lexicon1[word])\n",
    "print(pred_lexicon2[word])\n",
    "print(pred_lexicon3[word])\n",
    "print(pred_lexicon4[word])\n",
    "print(gold_lexicon[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "above-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = dict()\n",
    "for a in apps:\n",
    "    pred_all[a] = obj.read_files(apps[a])\n",
    "\n",
    "pred_all[\"Gold\"] = gold_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "average-average",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NED</th>\n",
       "      <th>JW</th>\n",
       "      <th>EMT</th>\n",
       "      <th>SEM_JW</th>\n",
       "      <th>SEM_EMT</th>\n",
       "      <th>Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>सकते</td>\n",
       "      <td>सकते</td>\n",
       "      <td>सकते</td>\n",
       "      <td>सकते</td>\n",
       "      <td>सकते</td>\n",
       "      <td>सका</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>सूते</td>\n",
       "      <td>सके</td>\n",
       "      <td>सकेत</td>\n",
       "      <td>सकता</td>\n",
       "      <td>सकती</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>सहते</td>\n",
       "      <td>सकता</td>\n",
       "      <td>घसकत</td>\n",
       "      <td>सकती</td>\n",
       "      <td>सकता</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>सके</td>\n",
       "      <td>सकती</td>\n",
       "      <td>सहकत</td>\n",
       "      <td>सके</td>\n",
       "      <td>सको</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>सकता</td>\n",
       "      <td>सकति</td>\n",
       "      <td>-</td>\n",
       "      <td>सकें</td>\n",
       "      <td>सका</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NED    JW   EMT SEM_JW SEM_EMT Gold\n",
       "1  सकते  सकते  सकते   सकते    सकते  सका\n",
       "2  सूते   सके  सकेत   सकता    सकती    -\n",
       "3  सहते  सकता  घसकत   सकती    सकता    -\n",
       "4   सके  सकती  सहकत    सके     सको    -\n",
       "5  सकता  सकति     -   सकें     सका    -"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"सकते\"\n",
    "comp = dict()\n",
    "for a in pred_all:\n",
    "    comp[a] = list(pred_all[a][word].keys())[:5]\n",
    "    comp[a] = {i+1: comp[a][i] if i < len(comp[a]) else \"-\" for i in range(5)}\n",
    "df = pd.DataFrame(comp)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "stylish-optics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'यात्रा': 1.0,\n",
       " 'यात्राएँ': 0.9249999999999999,\n",
       " 'यात्री': 0.9,\n",
       " 'यात्रायें': 0.8999999999999999,\n",
       " 'मात्रा': 0.888888888888889}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_all[\"JW\"][word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "green-worst",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'यात्रा'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-6125f65016c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"JW\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"corr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'यात्रा'"
     ]
    }
   ],
   "source": [
    "all_results[\"JW\"][\"corr\"][word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ultimate-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_results[\"sem_emod\"][\"/corr\"].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "boolean-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['क्या', 'तुमने', 'दोपहर', 'का', 'खाना', 'खाया', 'तुम', 'मेरे', 'साथ', 'आओगे', 'कैसे', 'आये', 'खोलें', 'वो', 'आयेगा', 'तुम्हारा', 'पसंदीडा', 'रंग', 'कौन', 'सा', 'हैं', 'कल', 'बस', 'से', 'आयी', 'आखिरी', 'सवाल', 'थे', 'सबसे', 'मीठा', 'फल', 'कौनसा', 'एक', 'मुझे', 'अपना', 'पेन', 'दे', 'सकते', 'हो', 'आप', 'क्यों', 'सोये', 'सेव', 'रहा', 'नाम', 'वे', 'वहाँ', 'बैठे', 'परीक्षा', 'लिख', 'उसने', 'यह', 'मैनेजर', 'कैबिन', 'कहाँ', 'किताब', 'खोलेंगे', 'आइये', 'हें', 'मैं', 'जवाब', 'होगा', 'हाँ', 'तुम्हें', 'प्यार', 'करता', 'करती', 'हूँ', 'दौड़ना', 'कार', 'चलते', 'खोलना', 'चलना', 'कितने', 'लिए', 'हिन्दी', 'न्युज़पेपर', 'अच्छा', 'कौंसी', 'कहानी', 'बताय्', 'बैठना', 'लिया', 'था', 'आपका', 'खत', 'लिखा', 'खा', 'बाग', 'लाया', 'बॉक्स', 'उठा', 'उसे', 'जाने', 'को', 'कहा', 'में', 'कितना', 'पैसा', 'दिया', 'किस', 'भारतीय', 'राज्य', 'की', 'जनसंख्या', 'ज्यादा', 'रास्ते', 'चाहिए', 'जायेगा', 'खायेगा', 'मैने', 'पिछले', 'सफ्तह', 'फिल्म', 'देखी', 'सकता', 'हाथ', 'रात', 'भर', 'सोया', 'करूँ', 'खाइये', 'यात्रा', 'कैसी', 'थी', 'तुम्हारे', 'आऊँगा', 'करते', 'दोगे', 'पीना', 'किया', 'कौनसे', 'कमरे', 'आया', 'आयेंगे', 'जाइये', 'एक्सम', 'गया', 'चला'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_lexicon.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "governmental-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'क्या': {'का': 21, 'करे': 1, 'कर': 1}, 'तुमने': {'तू': 6}, 'दोपहर': {'दोपहर': 1, 'मे': 1}, 'का': {'खाना': 1, 'का': 1}, 'खाना': {'खैला': 1}, 'खाया': {'हवा': 1, 'खैलास': 1}, 'तुम': {'तू': 16}, 'मेरे': {'हमरा': 1, 'हमरी': 1}, 'साथ': {'साथ': 2}, 'आओगे': {'चाल्बा': 1}, 'कैसे': {'कैसे': 3, 'आयला': 1}, 'आये': {'हव': 2, 'आयलाह': 1, 'आइल': 1}, 'खोलें': {'खुल्ला': 1}, 'वो': {'ऊऊ': 7, 'हौ': 2, 'रात': 1}, 'आयेगा': {'आई': 1}, 'तुम्हारा': {'तोहर': 2}, 'पसंदीडा': {'पसंदीडा': 1}, 'रंग': {'रंग': 1}, 'कौन': {'कौन': 1}, 'सा': {'सा': 1}, 'हैं': {'हा': 8, 'बा': 2, 'बाड़ा': 1}, 'कल': {'कल': 2}, 'बस': {'बस': 1}, 'से': {'से': 1, 'आयला': 1}, 'आयी': {'आइलास': 1}, 'आखिरी': {'अंतिम': 1}, 'सवाल': {'प्रशना': 3, 'रहल': 2}, 'थे': {'हा': 1, 'थे': 1}, 'सबसे': {'सबसे': 3, 'कौन': 2}, 'मीठा': {'मीठ्': 1}, 'फल': {'फल': 1, 'कौन': 1}, 'कौनसा': {'सा': 2}, 'एक': {'आ': 1}, 'मुझे': {'हमरा': 3, 'हम': 1}, 'अपना': {'के': 1, 'अपना': 1}, 'पेन': {'पेन': 2}, 'दे': {'दे': 1}, 'सकते': {'सका': 3}, 'हो': {'तारा': 3, 'ला': 2}, 'आप': {'क्याहे': 2, 'कौन': 2, 'आप': 1, 'कैसन': 1}, 'क्यों': {'सूट': 1, 'कहे': 5, 'दहलास': 1}, 'सोये': {'गेल': 1, 'सत्ला': 2, 'हा': 1}, 'सेव': {'आ': 2, 'सेब': 3}, 'रहा': {'खाता': 1}, 'नाम': {'नाव': 2}, 'वे': {'ऊऊ': 1}, 'वहाँ': {'लोग': 1, 'यहाँ': 1}, 'बैठे': {'बैठे': 1}, 'परीक्षा': {'परीक्षा': 1}, 'लिख': {'लिख': 1}, 'उसने': {'हौ': 4, 'ऊऊ': 4}, 'यह': {'ए': 1, 'ई': 2}, 'मैनेजर': {'मैनेजर': 1}, 'कैबिन': {'कैबिन': 1}, 'कहाँ': {'कहाँ': 3, 'सुत्तल': 1, 'रहला': 1}, 'किताब': {'किताब': 2}, 'खोलेंगे': {'खुल्ली': 1}, 'आइये': {'आऊँ': 1}, 'हें': {'बा': 2}, 'मैं': {'हम': 5, 'में': 4}, 'जवाब': {'उत्तर': 1}, 'होगा': {'होई': 1}, 'हाँ': {'हाँ': 2}, 'तुम्हें': {'तहरा': 1, 'टोके': 2}, 'प्यार': {'से': 2, 'प्यार': 1}, 'करता': {'प्यार': 1}, 'करती': {'करे': 1}, 'हूँ': {'नि': 1, 'बानी': 1, 'सकेनी': 1}, 'दौड़ना': {'दौड़': 1}, 'कार': {'कार': 1}, 'चलते': {'चलवे': 1}, 'खोलना': {'खोल': 1}, 'चलना': {'चल': 1}, 'कितने': {'कौ': 2, 'लहला': 1}, 'लिए': {'हव': 1}, 'हिन्दी': {'हिन्दी': 1}, 'न्युज़पेपर': {'पेपर': 1}, 'अच्छा': {'आच्छा': 2, 'अच्छा': 1}, 'कौंसी': {'कौन': 1, 'सा': 1}, 'कहानी': {'कहानी': 1}, 'बताय्': {'सुनवाला': 1}, 'बैठना': {'बैठ': 1}, 'लिया': {'खैले': 1, 'बा': 1}, 'था': {'बा': 4}, 'आपका': {'तोहर': 1}, 'खत': {'चित्ती': 1}, 'लिखा': {'लिखल': 1, 'लिखला': 1, 'लिखलास': 1}, 'खा': {'खा': 1, 'लेले': 1}, 'बाग': {'झोला': 1, 'लेके': 1}, 'लाया': {'आयल': 1, 'बा': 1}, 'बॉक्स': {'बॉक्स्वा': 1}, 'उठा': {'उठा': 1}, 'उसे': {'उनके': 1}, 'जाने': {'जाये': 1}, 'को': {'के': 1}, 'कहा': {'कहलाह': 1, 'कहल': 1}, 'में': {'हम': 1}, 'कितना': {'केतना': 1}, 'पैसा': {'दहला': 1, 'पैसा': 1}, 'दिया': {'सा': 1, 'हा': 1}, 'किस': {'भारत': 1, 'रास्ता': 1}, 'भारतीय': {'के': 1}, 'राज्य': {'से': 1}, 'की': {'राज्य': 1, 'का': 1}, 'जनसंख्या': {'मे': 1}, 'ज्यादा': {'जयदा': 1, 'लोग': 1, 'हैं': 1}, 'रास्ते': {'से': 2}, 'चाहिए': {'जाईन': 1}, 'जायेगा': {'झाई': 1}, 'खायेगा': {'खाई': 1}, 'मैने': {'पिछला': 1}, 'पिछले': {'हफ़्ता': 1, 'हम': 1}, 'सफ्तह': {'एगो': 1}, 'फिल्म': {'फिल्म': 1}, 'देखी': {'देखलिन': 1}, 'सकता': {'कर': 1}, 'हाथ': {'हाथ': 1}, 'रात': {'भर': 1}, 'भर': {'सुत्तल': 1}, 'सोया': {'बा': 1}, 'करूँ': {'के': 2, 'चाहीं': 1}, 'खाइये': {'खाओ': 1}, 'यात्रा': {'सफर': 1}, 'कैसी': {'कैसन': 1}, 'थी': {'रहल': 1}, 'तुम्हारे': {'तहरा': 1}, 'आऊँगा': {'आयेम': 1}, 'करते': {'करे': 1}, 'दोगे': {'देबा': 1}, 'पीना': {'पीले': 1}, 'किया': {'दहला': 1}, 'कौनसे': {'से': 1}, 'कमरे': {'कमरे': 1}, 'आया': {'आ': 1, 'चुकल': 1}, 'आयेंगे': {'आई': 1}, 'जाइये': {'जा': 1}, 'एक्सम': {'परीक्षा': 1, 'में': 1}, 'गया': {'गयिल': 1, 'चुकल': 1}, 'चला': {'जा': 1}}\n"
     ]
    }
   ],
   "source": [
    "print(gold_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-liabilities",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
