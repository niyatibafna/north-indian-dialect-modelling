{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "immediate-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS SUCH AS CHARACTER/WORD FREQUENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungarian-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawled_data import CrawledData\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "under-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affecting-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files for rajasthani\n",
      "Getting files for gujarati\n",
      "Getting files for hindi-urdu\n",
      "Getting files for magahi\n",
      "Getting files for awadhi\n",
      "Getting files for bajjika\n",
      "Getting files for .DS_Store\n",
      "Getting files for braj\n",
      "Getting files for bhojpuri\n",
      "Getting files for garwali\n",
      "Getting files for chattisgarhi\n",
      "Getting files for maithili\n",
      "Getting files for sanskrit\n",
      "Getting files for pali\n",
      "Getting files for angika\n",
      "Getting files for hariyanvi\n",
      "Getting files for sindhi\n",
      "Getting files for marathi\n",
      "Getting files for nepali\n"
     ]
    }
   ],
   "source": [
    "# data_obj = CrawledData(\"../data/crawled/folksongs/\")\n",
    "data_obj = CrawledData(\"../data/crawled/poetry/\")\n",
    "data_obj.read_crawled_data(remove_punctuation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-diana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_obj.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "julian-matter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'अगर चन्दन का बण्या रे किवाड़ / निमाड़ी',\n",
       " 'text': 'अगर चन्दन का बण्या रे किवाड़ , बावन चन्दन की कोठड़ी , कोठड़ी मऽ बठ्या राणी रनुबाई नार हो , बाळा कुंवर की मावली । भोळा हो धणियेर , भोळा तुम्हारो राज , तो नव दिन पियर हम जावां जी । तुम देवी मूरख गंवार , नव दिन पीयर मत जाओ । तपऽ तपऽ चैत केरो घाम , कड़ी को बाळो कुम्हलई जासे तुम्हारा बाला खऽ राखो तुम्हारा पास , नव दिन पियर हम जावां जी । ।',\n",
       " 'lang': {'dev': 'निमाड़ी', 'rom': 'nimaadi'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obj.data[\"nimaadi\"][\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepting-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHARACTER FREQUENCY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "traditional-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_by_char = dict()\n",
    "bad_chars = [\"\\n\", \"\\t\", \" \"]\n",
    "for lang in data_obj.data:\n",
    "    acc_data = \"\".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]])\n",
    "    lang_by_char[lang] = Counter(acc_data)\n",
    "    total = sum(lang_by_char[lang].values())\n",
    "    for key, val in lang_by_char[lang].items():\n",
    "        lang_by_char[lang][key] = round(val*100/total, 3)\n",
    "    for bad_char in bad_chars:\n",
    "        del lang_by_char[lang][bad_char] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wireless-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_freq = pd.DataFrame(lang_by_char).fillna(0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "trained-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_freq.to_csv(\"stats_outputs/character_frequency_poetry.csv\", sep = \"\\t\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aggregate-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lang in lang_by_char:\n",
    "#     print(sum(lang_by_char[lang].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governmental-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj.read_crawled_data(remove_punctuation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "failing-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORD FREQUENCY TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "registered-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = dict()\n",
    "bad_chars = [\"\\n\", \"\\t\", \" \", \"\"]\n",
    "for lang in data_obj.data:\n",
    "    acc_data = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]])\n",
    "#     print(acc_data[:500])\n",
    "    word_freq[lang] = Counter(acc_data.split())\n",
    "    total = sum(word_freq[lang].values())\n",
    "    for key, val in word_freq[lang].items():\n",
    "        word_freq[lang][key] = round(val*100/total, 3)\n",
    "    for bad_char in bad_chars:\n",
    "        del word_freq[lang][bad_char] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recorded-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lang in word_freq:\n",
    "#     print(lang)\n",
    "for lang in word_freq:\n",
    "    word_freq[lang] = sorted(list(word_freq[lang].items()), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "integrated-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lang in word_freq:\n",
    "#     print(lang)\n",
    "#     print(word_freq[lang][-100:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comparable-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stats_outputs/word_frequency.json\", \"w\") as f:\n",
    "    json.dump(word_freq, f, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "entitled-thompson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.49000000000984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p[1] for p in word_freq[\"nimaadi\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-plant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-remainder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-decade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "literary-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK FOR ROMAN CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scheduled-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_words = list()\n",
    "for lang in data_obj.data:\n",
    "    acc_data = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]]).split()\n",
    "    for word in acc_data:\n",
    "        for c in word:\n",
    "            if c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "                non_words.append(word+\" \"+lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "united-bristol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adequate-honey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(non_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exterior-messaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(non_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-charles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-virus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-cancellation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "wound-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "consistent-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = dict()\n",
    "for lang in data_obj.data:\n",
    "    acc_data[lang] = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "interpreted-house",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "czech-chile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-ballet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
