{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "immediate-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS SUCH AS CHARACTER/WORD FREQUENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hungarian-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "from crawled_data import CrawledData\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "under-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "affecting-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files for rajasthani\n",
      "Getting files for gujarati\n",
      "Getting files for himachali\n",
      "Getting files for hindi-urdu\n",
      "Getting files for magahi\n",
      "Getting files for awadhi\n",
      "Getting files for punjabi\n",
      "Getting files for koraku\n",
      "Getting files for baiga\n",
      "Getting files for .DS_Store\n",
      "Getting files for nimaadi\n",
      "Getting files for khadi_boli\n",
      "Getting files for bhojpuri\n",
      "Getting files for garwali\n",
      "Getting files for chattisgarhi\n",
      "Getting files for brajbhasha\n",
      "Getting files for bhil\n",
      "Getting files for sanskrit\n",
      "Getting files for angika\n",
      "Getting files for hariyanvi\n",
      "Getting files for kannauji\n",
      "Getting files for bundeli\n",
      "Getting files for bangla\n",
      "Getting files for malwi\n",
      "Getting files for marathi\n",
      "Getting files for kumaoni\n",
      "Getting files for bhadavari\n",
      "dict_keys(['rajasthani', 'gujarati', 'himachali', 'hindi-urdu', 'magahi', 'awadhi', 'punjabi', 'koraku', 'baiga', 'nimaadi', 'khadi_boli', 'bhojpuri', 'garwali', 'chattisgarhi', 'brajbhasha', 'bhil', 'sanskrit', 'angika', 'hariyanvi', 'kannauji', 'bundeli', 'bangla', 'malwi', 'marathi', 'kumaoni', 'bhadavari'])\n"
     ]
    }
   ],
   "source": [
    "data_obj = CrawledData()\n",
    "data_obj.read_crawled_data(\"../data/crawled/folksongs/\", remove_punctuation = True)\n",
    "# print(data_obj.data.keys())\n",
    "# data_obj.read_crawled_data(\"../data/crawled/poetry/\", remove_punctuation = True)\n",
    "print(data_obj.data.keys())\n",
    "acc_data = dict()\n",
    "for lang in data_obj.data:\n",
    "    acc_data[lang] = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confident-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files for rajasthani\n",
      "Getting files for gujarati\n",
      "Getting files for hindi-urdu\n",
      "Getting files for magahi\n",
      "Getting files for awadhi\n",
      "Getting files for bajjika\n",
      "Getting files for .DS_Store\n",
      "Getting files for bhojpuri\n",
      "Getting files for garwali\n",
      "Getting files for chattisgarhi\n",
      "Getting files for brajbhasha\n",
      "Getting files for maithili\n",
      "Getting files for sanskrit\n",
      "Getting files for pali\n",
      "Getting files for angika\n",
      "Getting files for hariyanvi\n",
      "Getting files for sindhi\n",
      "Getting files for marathi\n",
      "Getting files for nepali\n"
     ]
    }
   ],
   "source": [
    "data_obj_p = CrawledData()\n",
    "# data_obj.read_crawled_data(\"../data/crawled/folksongs/\", remove_punctuation = True)\n",
    "# print(data_obj.data.keys())\n",
    "data_obj_p.read_crawled_data(\"../data/crawled/poetry/\", remove_punctuation = True)\n",
    "acc_data_p = dict()\n",
    "for lang in data_obj.data:\n",
    "    acc_data_p[lang] = \" \".join([data_obj_p.data[lang][file_id][\"text\"] for file_id in data_obj_p.data[lang]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "collect-diana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Langs for folksongs\n",
    "len(data_obj.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fabulous-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Langs for poetry\n",
    "len(data_obj_p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "suburban-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = set(data_obj.data).union(data_obj_p.data)\n",
    "len(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "computational-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_table = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "stats_table[\"folksongs\"] = defaultdict(lambda: 0, {lang:len(data_obj.data[lang]) for lang in data_obj.data})\n",
    "stats_table[\"poetry\"] = defaultdict(lambda: 0, {lang:len(data_obj_p.data[lang]) for lang in data_obj_p.data})\n",
    "stats_table[\"folksongs #tokens\"] = defaultdict(lambda: 0, {lang:len(acc_data[lang].split()) for lang in data_obj.data})\n",
    "stats_table[\"poetry #tokens\"] = defaultdict(lambda: 0, {lang:len(acc_data_p[lang].split()) for lang in data_obj_p.data})\n",
    "stats_table[\"total pieces\"] = {lang:stats_table[\"folksongs\"][lang]+stats_table[\"poetry\"][lang] for lang in langs}\n",
    "stats_table[\"total #tokens\"] = {lang:stats_table[\"folksongs #tokens\"][lang]+stats_table[\"poetry #tokens\"][lang] for lang in langs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "varied-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stats_outputs/corpus_counts.json\", \"w\") as f:\n",
    "    json.dump(stats_table, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-edwards",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "refined-costs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "compact-arctic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-wedding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-veteran",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-community",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "infectious-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_range = range(2305, 2404)\n",
    "for lang in data_obj.data:\n",
    "    acc_data[lang] = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]])\n",
    "    acc_data[lang] = \"\".join([c if ord(c) in dev_range else \" \" for c in acc_data[lang]])\n",
    "    acc_data[lang] = \" \".join(acc_data[lang].split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepting-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHARACTER FREQUENCY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "traditional-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_by_char = dict()\n",
    "bad_chars = [\"\\n\", \"\\t\", \" \"]\n",
    "for lang in data_obj.data:\n",
    "    lang_by_char[lang] = Counter(acc_data[lang])\n",
    "    total = sum(lang_by_char[lang].values())\n",
    "    for key, val in lang_by_char[lang].items():\n",
    "        lang_by_char[lang][key] = round(val*100/total, 3)\n",
    "    for bad_char in bad_chars:\n",
    "        del lang_by_char[lang][bad_char] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wireless-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_freq = pd.DataFrame(lang_by_char).fillna(0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trained-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_freq.to_csv(\"stats_outputs/character_frequency.csv\", sep = \"\\t\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aggregate-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lang in lang_by_char:\n",
    "#     print(sum(lang_by_char[lang].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governmental-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_obj.read_crawled_data(remove_punctuation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "failing-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORD FREQUENCY TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "registered-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = dict()\n",
    "bad_chars = [\"\\n\", \"\\t\", \" \", \"\"]\n",
    "for lang in data_obj.data:\n",
    "#     acc_data = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]])\n",
    "#     print(acc_data[:500])\n",
    "    word_freq[lang] = Counter(acc_data[lang].split())\n",
    "    total = sum(word_freq[lang].values())\n",
    "    for key, val in word_freq[lang].items():\n",
    "        word_freq[lang][key] = round(val*100/total, 3)\n",
    "    for bad_char in bad_chars:\n",
    "        del word_freq[lang][bad_char] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recorded-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lang in word_freq:\n",
    "#     print(lang)\n",
    "for lang in word_freq:\n",
    "    word_freq[lang] = sorted(list(word_freq[lang].items()), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "integrated-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lang in word_freq:\n",
    "#     print(lang)\n",
    "#     print(word_freq[lang][-100:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comparable-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stats_outputs/word_frequency.json\", \"w\") as f:\n",
    "    json.dump(word_freq, f, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "entitled-thompson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.81600000001346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p[1] for p in word_freq[\"nimaadi\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-plant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-remainder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-decade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "literary-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK FOR ROMAN CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scheduled-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_words = list()\n",
    "for lang in data_obj.data:\n",
    "    acc_data = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]]).split()\n",
    "    for word in acc_data:\n",
    "        for c in word:\n",
    "            if c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "                non_words.append(word+\" \"+lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "united-bristol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adequate-honey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(non_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exterior-messaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(non_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-charles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-virus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-cancellation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "wound-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "consistent-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = dict()\n",
    "for lang in data_obj.data:\n",
    "    acc_data[lang] = \" \".join([data_obj.data[lang][file_id][\"text\"] for file_id in data_obj.data[lang]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "interpreted-house",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "czech-chile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-ballet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
